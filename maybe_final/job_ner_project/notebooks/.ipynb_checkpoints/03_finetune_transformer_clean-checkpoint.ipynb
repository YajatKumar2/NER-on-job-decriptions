{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e90c005-b09c-4dba-b088-f30a405278ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.57.2)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/lib/python3.13/site-packages (0.4.6)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.13/site-packages (1.12.0)\n",
      "Requirement already satisfied: seqeval in /opt/anaconda3/lib/python3.13/site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.13/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/anaconda3/lib/python3.13/site-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers datasets evaluate accelerate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76875f6b-7ce0-41ed-9d9a-c1cad0cb1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in a notebook cell\n",
    "!pip install -q transformers datasets evaluate seqeval accelerate\n",
    "!pip install -q pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7df0948-5c83-46b6-baa7-3610a4c9dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 2\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"   # quiet warning\n",
    "os.environ[\"HF_HOME\"] = os.environ.get(\"HF_HOME\", os.path.expanduser(\"~/.cache/huggingface\"))\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f91cf37-e094-4727-8c9e-a38075f14bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV rows: 569\n",
      "Loaded sequences: 20\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 3\n",
    "csv_path = \"../data/annotated/job_ner_annotations_full_20_jds.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"CSV rows:\", len(df))\n",
    "\n",
    "# rebuild sequences grouped by sentence_id (sorted)\n",
    "sentences = []\n",
    "labels = []\n",
    "ids = []\n",
    "for sid, grp in df.groupby(\"sentence_id\", sort=True):\n",
    "    toks = grp[\"token\"].tolist()\n",
    "    labs = grp[\"label\"].tolist()\n",
    "    sentences.append(toks)\n",
    "    labels.append(labs)\n",
    "    ids.append(int(sid))\n",
    "\n",
    "print(\"Loaded sequences:\", len(sentences))\n",
    "# Basic sanity: each seq should have equal tokens/labels\n",
    "bad = [(i, len(t), len(l)) for i,(t,l) in enumerate(zip(sentences, labels)) if len(t)!=len(l)]\n",
    "assert len(bad)==0, f\"Alignment errors found: {bad}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ed3773-6dec-4d0d-b72c-38bd05bef36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test counts: 14 2 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 14\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook cell 4\n",
    "# 80/10/10 split by sequence count (already used earlier)\n",
    "train_tokens = sentences[:16]\n",
    "train_labels = labels[:16]\n",
    "\n",
    "val_tokens = train_tokens[-2:]\n",
    "val_labels = train_labels[-2:]\n",
    "\n",
    "train_tokens = train_tokens[:-2]\n",
    "train_labels = train_labels[:-2]\n",
    "\n",
    "test_tokens = sentences[16:]\n",
    "test_labels = labels[16:]\n",
    "\n",
    "print(\"Train/Val/Test counts:\", len(train_tokens), len(val_tokens), len(test_tokens))\n",
    "\n",
    "def build_hf_dataset(token_seqs, label_seqs):\n",
    "    return Dataset.from_list([{\"tokens\": t, \"labels\": l} for t,l in zip(token_seqs, label_seqs)])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": build_hf_dataset(train_tokens, train_labels),\n",
    "    \"validation\": build_hf_dataset(val_tokens, val_labels),\n",
    "    \"test\": build_hf_dataset(test_tokens, test_labels),\n",
    "})\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec76bd8c-bc6f-4709-9d30-2576a75797cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels: 16\n",
      "['B-COMPANY',\n",
      " 'B-DEGREE_MAJOR',\n",
      " 'B-EDUCATION_LEVEL',\n",
      " 'B-EMPLOYEMENT_TYPE',\n",
      " 'B-FRAMEWORK',\n",
      " 'B-JOB_TITLE',\n",
      " 'B-LOCATION',\n",
      " 'B-PROGRAMMING_LANGUAGE',\n",
      " 'B-SKILL_TECH',\n",
      " 'B-TOOL',\n",
      " 'I-DEGREE_MAJOR',\n",
      " 'I-FRAMEWORK',\n",
      " 'I-JOB_TITLE',\n",
      " 'I-SKILL_TECH',\n",
      " 'I-TOOL',\n",
      " 'O']\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 5\n",
    "# derive BIO label set from dataset (keeps order deterministic)\n",
    "unique_labels = sorted({lab for seq in labels for lab in seq})\n",
    "# ensure O present\n",
    "if \"O\" not in unique_labels:\n",
    "    unique_labels.append(\"O\")\n",
    "\n",
    "label_list = unique_labels\n",
    "label_to_id = {l:i for i,l in enumerate(label_list)}\n",
    "id_to_label = {i:l for l,i in label_to_id.items()}\n",
    "\n",
    "print(\"Num labels:\", len(label_list))\n",
    "pprint(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f6c5a8-7888-47e0-87e3-a28ee70849d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db56ec7ed7d4c29b7ef9c26906f5502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25394d386f7345778bff151e3d2ecad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e4389890f746f0953c30150dfff65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 14\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook cell 6\n",
    "# For a fast smoke test use a tiny model; later swap to distilbert/bert\n",
    "model_checkpoint = \"sshleifer/tiny-distilbert-base-cased\"  # tiny, quick download\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "def hf_tokenize_align(batch):\n",
    "    # tokenizes with is_split_into_words=True and aligns labels -> token ids\n",
    "    tokenized = tokenizer(batch[\"tokens\"], is_split_into_words=True, truncation=True)\n",
    "    all_labels = []\n",
    "    for i, label_seq in enumerate(batch[\"labels\"]):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "        aligned = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned.append(-100)  # ignore in loss\n",
    "            else:\n",
    "                aligned.append(label_to_id[label_seq[word_idx]])\n",
    "        all_labels.append(aligned)\n",
    "    tokenized[\"labels\"] = all_labels\n",
    "    return tokenized\n",
    "\n",
    "# Apply mapping\n",
    "tokenized_datasets = dataset.map(hf_tokenize_align, batched=True, remove_columns=[\"tokens\",\"labels\"])\n",
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2d7c0e-f883-4937-b981-aed0902004a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-piece : label-id (first 60)\n",
      "[CLS]        -> -100\n",
      "We           -> 15\n",
      "are          -> 15\n",
      "looking      -> 15\n",
      "for          -> 15\n",
      "a            -> 15\n",
      "Data         -> 5\n",
      "Scientist    -> 12\n",
      "to           -> 15\n",
      "join         -> 15\n",
      "our          -> 15\n",
      "Bangalore    -> 6\n",
      "office       -> 15\n",
      ".            -> 15\n",
      "The          -> 15\n",
      "ideal        -> 15\n",
      "candidate    -> 15\n",
      "has          -> 15\n",
      "experience   -> 15\n",
      "with         -> 15\n",
      "Python       -> 7\n",
      ",            -> 15\n",
      "S            -> 9\n",
      "##QL         -> 9\n",
      ",            -> 15\n",
      "and          -> 15\n",
      "machine      -> 8\n",
      "learning     -> 13\n",
      "framework    -> 15\n",
      "##s          -> 15\n",
      "like         -> 15\n",
      "Ten          -> 4\n",
      "##sor        -> 4\n",
      "##F          -> 4\n",
      "##low        -> 4\n",
      "or           -> 15\n",
      "P            -> 4\n",
      "##y          -> 4\n",
      "##T          -> 4\n",
      "##or         -> 4\n",
      "##ch         -> 4\n",
      ".            -> 15\n",
      "Employment   -> 15\n",
      "type         -> 15\n",
      "is           -> 15\n",
      "full         -> 3\n",
      "-            -> 3\n",
      "time         -> 3\n",
      ".            -> 15\n",
      "[SEP]        -> -100\n",
      "label id range: 0 15 num labels: 16\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 7\n",
    "# Inspect one example (converted token ids -> tokens) to confirm alignment\n",
    "i = 0\n",
    "ex = tokenized_datasets[\"train\"][i]\n",
    "tokens_wp = tokenizer.convert_ids_to_tokens(ex[\"input_ids\"])\n",
    "labels_ids = ex[\"labels\"]\n",
    "# show pairs (first 60)\n",
    "pairs = list(zip(tokens_wp[:60], labels_ids[:60]))\n",
    "print(\"token-piece : label-id (first 60)\")\n",
    "for t,l in pairs:\n",
    "    print(f\"{t:12s} -> {l}\")\n",
    "# quick label id range check\n",
    "all_lab_ids = []\n",
    "for ex in tokenized_datasets[\"train\"]:\n",
    "    all_lab_ids.extend([x for x in ex[\"labels\"] if x!=-100])\n",
    "print(\"label id range:\", min(all_lab_ids), max(all_lab_ids), \"num labels:\", len(label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b8f88b-c69d-4995-a55e-7ded5e58890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/tiny-distilbert-base-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at sshleifer/tiny-distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 2]) in the checkpoint and torch.Size([16, 2]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([16]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. num_labels: 16\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 8\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# load model; ignore_mismatched_sizes helps if checkpoint head doesn't match our num_labels\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "print(\"Model loaded. num_labels:\", model.config.num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ba5759-aef6-4015-b18e-83bed3bda2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/tiny-distilbert-base-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced classifier. hidden_size: 2 num_labels: 16\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 1) load the base model WITHOUT forcing a classifier shape\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "# 2) create a new classification head sized to your labels\n",
    "hidden_size = base_model.config.hidden_size\n",
    "num_labels = len(label_list)\n",
    "\n",
    "new_classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "# initialize new head (Xavier init is common)\n",
    "nn.init.xavier_uniform_(new_classifier.weight)\n",
    "if new_classifier.bias is not None:\n",
    "    nn.init.zeros_(new_classifier.bias)\n",
    "\n",
    "# 3) assign the new head to the model\n",
    "# common attribute names: `classifier` or `score` depending on model type.\n",
    "# Many BERT-like models use `classifier`. If not, inspect model children.\n",
    "if hasattr(base_model, \"classifier\"):\n",
    "    base_model.classifier = new_classifier\n",
    "else:\n",
    "    # fallback: find a linear layer name to replace (less common)\n",
    "    for name, module in base_model.named_modules():\n",
    "        # look for first Linear in top-level modules (not perfect but works)\n",
    "        if isinstance(module, nn.Linear):\n",
    "            parent_name = name.rsplit(\".\", 1)[0]\n",
    "            setattr(base_model, parent_name, new_classifier)\n",
    "            break\n",
    "\n",
    "# 4) update config label maps\n",
    "base_model.config.num_labels = num_labels\n",
    "base_model.config.id2label = id_to_label\n",
    "base_model.config.label2id = label_to_id\n",
    "\n",
    "# Use base_model as `model` from now on\n",
    "model = base_model\n",
    "print(\"Replaced classifier. hidden_size:\", hidden_size, \"num_labels:\", num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da154488-91ec-4ac8-85c0-8d3945ce7357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.config.num_labels: 16\n",
      "len(label_list): 16\n",
      "id2label keys sample: [(0, 'B-COMPANY'), (1, 'B-DEGREE_MAJOR'), (2, 'B-EDUCATION_LEVEL'), (3, 'B-EMPLOYEMENT_TYPE'), (4, 'B-FRAMEWORK')]\n",
      "Classifier module: <class 'torch.nn.modules.linear.Linear'> torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1) config check\n",
    "print(\"model.config.num_labels:\", model.config.num_labels)\n",
    "print(\"len(label_list):\", len(label_list))\n",
    "print(\"id2label keys sample:\", list(model.config.id2label.items())[:5])\n",
    "\n",
    "# 2) show classifier shape\n",
    "print(\"Classifier module:\", type(model.classifier), getattr(model.classifier, \"weight\", None).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e289c996-02a9-4022-94d5-349dc24de267",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- fixed TrainingArguments + Trainer (use this cell instead) ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[0;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/finetuned-small-debug\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,        \u001b[38;5;66;03m# EVALUATE every epoch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;66;03m# SAVE every epoch (must match evaluation_strategy)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,      \u001b[38;5;66;03m# small to avoid OOM (use 2 if you have GPU memory)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     11\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,      \u001b[38;5;66;03m# effective batch = 1 * 4\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     13\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     14\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     15\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     16\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,        \u001b[38;5;66;03m# now valid because eval & save strategies match\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Smoke test: run a short train\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# --- fixed TrainingArguments + Trainer (use this cell instead) ---\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/finetuned-small-debug\",\n",
    "    evaluation_strategy=\"epoch\",        # EVALUATE every epoch\n",
    "    save_strategy=\"epoch\",              # SAVE every epoch (must match evaluation_strategy)\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,      # small to avoid OOM (use 2 if you have GPU memory)\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,      # effective batch = 1 * 4\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,        # now valid because eval & save strategies match\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Smoke test: run a short train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adc8bcc-73af-4475-92bd-464fa329fbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Notebook cell 11\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/finetuned-small-debug\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Notebook cell 11\n",
    "metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(metrics)\n",
    "\n",
    "trainer.save_model(\"models/finetuned-small-debug\")\n",
    "tokenizer.save_pretrained(\"models/finetuned-small-debug\")\n",
    "print(\"Saved model to models/finetuned-small-debug\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cbb5d-7b4c-4cc2-ae65-458b42398a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
