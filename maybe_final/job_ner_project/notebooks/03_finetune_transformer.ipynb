{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355c4a3c-a088-4358-9185-0e586fc9809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 1\n",
    "# Install required libs (run in a notebook cell)\n",
    "!pip install -q transformers datasets seqeval evaluate accelerate\n",
    "!pip install -q tokenizers\n",
    "\n",
    "# If you haven't already:\n",
    "!pip install -q pandas scikit-learn\n",
    "\n",
    "# Then imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed\n",
    ")\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3663b3c4-f579-4467-a7a2-b78400ee11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 sequences\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 2\n",
    "csv_path = \"../data/annotated/job_ner_annotations_full_20_jds.csv\"  # adjust path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()\n",
    "\n",
    "# Reconstruct tokens & labels per sentence_id (job id).\n",
    "sentences = []\n",
    "labels = []\n",
    "ids = []\n",
    "\n",
    "for sid, grp in df.groupby(\"sentence_id\", sort=True):\n",
    "    toks = grp[\"token\"].tolist()\n",
    "    labs = grp[\"label\"].tolist()\n",
    "    sentences.append(toks)\n",
    "    labels.append(labs)\n",
    "    ids.append(int(sid))\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92143bf9-073e-40af-ab98-a312991d11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes (sequences): 14 2 4\n",
      "train alignment issues: []\n",
      "val alignment issues: []\n",
      "test alignment issues: []\n",
      "{'labels': ['O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-JOB_TITLE',\n",
      "            'I-JOB_TITLE',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-LOCATION',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-PROGRAMMING_LANGUAGE',\n",
      "            'O',\n",
      "            'B-TOOL',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-SKILL_TECH',\n",
      "            'I-SKILL_TECH',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-FRAMEWORK',\n",
      "            'O',\n",
      "            'B-FRAMEWORK',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O',\n",
      "            'B-EMPLOYEMENT_TYPE',\n",
      "            'O'],\n",
      " 'tokens': ['We',\n",
      "            'are',\n",
      "            'looking',\n",
      "            'for',\n",
      "            'a',\n",
      "            'Data',\n",
      "            'Scientist',\n",
      "            'to',\n",
      "            'join',\n",
      "            'our',\n",
      "            'Bangalore',\n",
      "            'office',\n",
      "            '.',\n",
      "            'The',\n",
      "            'ideal',\n",
      "            'candidate',\n",
      "            'has',\n",
      "            'experience',\n",
      "            'with',\n",
      "            'Python',\n",
      "            ',',\n",
      "            'SQL',\n",
      "            ',',\n",
      "            'and',\n",
      "            'machine',\n",
      "            'learning',\n",
      "            'frameworks',\n",
      "            'like',\n",
      "            'TensorFlow',\n",
      "            'or',\n",
      "            'PyTorch',\n",
      "            '.',\n",
      "            'Employment',\n",
      "            'type',\n",
      "            'is',\n",
      "            'full-time',\n",
      "            '.']}\n",
      "HF datasets built and validated.\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 3\n",
    "train_tokens = sentences[:16]\n",
    "train_labels = labels[:16]\n",
    "\n",
    "test_tokens = sentences[16:]\n",
    "test_labels = labels[16:]\n",
    "\n",
    "# Optionally create a small validation from train (e.g., last 2 of train)\n",
    "val_tokens = train_tokens[-2:]\n",
    "val_labels = train_labels[-2:]\n",
    "train_tokens = train_tokens[:-2]\n",
    "train_labels = train_labels[:-2]\n",
    "\n",
    "print(\"Train/Val/Test sizes (sequences):\", len(train_tokens), len(val_tokens), len(test_tokens))\n",
    "\n",
    "# Make HF datasets from lists\n",
    "def build_hf_dataset(token_seqs, label_seqs):\n",
    "    records = []\n",
    "    for toks, labs in zip(token_seqs, label_seqs):\n",
    "        records.append({\"tokens\": toks, \"labels\": labs})\n",
    "    return Dataset.from_list(records)\n",
    "\n",
    "hf_train = build_hf_dataset(train_tokens, train_labels)\n",
    "hf_val = build_hf_dataset(val_tokens, val_labels)\n",
    "hf_test = build_hf_dataset(test_tokens, test_labels)\n",
    "\n",
    "dataset = DatasetDict({\"train\": hf_train, \"validation\": hf_val, \"test\": hf_test})\n",
    "dataset\n",
    "\n",
    "# quick check to ensure every sequence has same number of tokens and labels\n",
    "def check_alignment(token_seqs, label_seqs):\n",
    "    bad = []\n",
    "    for i, (t, l) in enumerate(zip(token_seqs, label_seqs)):\n",
    "        if len(t) != len(l):\n",
    "            bad.append((i, len(t), len(l)))\n",
    "    return bad\n",
    "\n",
    "print(\"train alignment issues:\", check_alignment(train_tokens, train_labels))\n",
    "print(\"val alignment issues:\", check_alignment(val_tokens, val_labels))\n",
    "print(\"test alignment issues:\", check_alignment(test_tokens, test_labels))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint({\"tokens\": train_tokens[0], \"labels\": train_labels[0]})\n",
    "\n",
    "\n",
    "#quick verify on HF datasets\n",
    "for split in [\"train\",\"validation\",\"test\"]:\n",
    "    ds = dataset[split]\n",
    "    # check that each row has tokens and labels and lengths match\n",
    "    for i in range(min(3, len(ds))):\n",
    "        t = ds[i][\"tokens\"]; l = ds[i][\"labels\"]\n",
    "        assert len(t) == len(l), f\"Mismatch in {split} row {i}: {len(t)} vs {len(l)}\"\n",
    "print(\"HF datasets built and validated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91335f58-1054-4bab-8a9b-b4083d300ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels: 16\n",
      "['B-COMPANY', 'B-DEGREE_MAJOR', 'B-EDUCATION_LEVEL', 'B-EMPLOYEMENT_TYPE', 'B-FRAMEWORK', 'B-JOB_TITLE', 'B-LOCATION', 'B-PROGRAMMING_LANGUAGE', 'B-SKILL_TECH', 'B-TOOL', 'I-DEGREE_MAJOR', 'I-FRAMEWORK', 'I-JOB_TITLE', 'I-SKILL_TECH', 'I-TOOL', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 4\n",
    "# Collect all unique labels in BIO form from dataset\n",
    "unique_labels = sorted({lab for labs in labels for lab in labs})\n",
    "# Ensure 'O' present\n",
    "if \"O\" not in unique_labels:\n",
    "    unique_labels.append(\"O\")\n",
    "unique_labels = sorted(unique_labels, key=lambda x: (x == \"O\", x))  # put O last or first as you like\n",
    "\n",
    "# But for token-classification we need unique entity tag types (B-xxx, I-xxx).\n",
    "label_list = unique_labels\n",
    "label_list\n",
    "# Create maps\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "id_to_label = {i: l for l, i in label_to_id.items()}\n",
    "\n",
    "print(\"Num labels:\", len(label_list))\n",
    "print(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d037cf-e4f9-49de-b22d-0b61c0decfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: /Users/yajatchowdary/.cache/huggingface/transformers/*\n"
     ]
    }
   ],
   "source": [
    "# run in a notebook cell\n",
    "!rm -rf ~/.cache/huggingface/transformers/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022527a6-1647-4c29-b405-3495008a7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokens: ['We', 'are', 'looking', 'for', 'a', 'Data', 'Scientist', 'to', 'join', 'our', 'Bangalore', 'office', '.', 'The', 'ideal', 'candidate', 'has', 'experience', 'with', 'Python', ',', 'SQL', ',', 'and', 'machine', 'learning', 'frameworks', 'like', 'TensorFlow', 'or', 'PyTorch', '.', 'Employment', 'type', 'is', 'full-time', '.']\n",
      "Example labels: ['O', 'O', 'O', 'O', 'O', 'B-JOB_TITLE', 'I-JOB_TITLE', 'O', 'O', 'O', 'B-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PROGRAMMING_LANGUAGE', 'O', 'B-TOOL', 'O', 'O', 'B-SKILL_TECH', 'I-SKILL_TECH', 'O', 'O', 'B-FRAMEWORK', 'O', 'B-FRAMEWORK', 'O', 'O', 'O', 'O', 'B-EMPLOYEMENT_TYPE', 'O']\n",
      "{'input_ids': [101, 1284, 1132, 1702, 1111, 170, 7154, 22985, 1106, 2866, 1412, 14560, 1701, 119, 1109, 7891, 3234, 1144, 2541, 1114, 23334, 117, 156, 22825, 117, 1105, 3395, 3776, 8297, 1116, 1176, 5157, 21484, 2271, 6737, 1137, 153, 1183, 1942, 1766, 1732, 119, 18340, 2076, 1110, 1554, 118, 1159, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [15, 15, 15, 15, 15, 15, 5, 12, 15, 15, 15, 6, 15, 15, 15, 15, 15, 15, 15, 15, 7, 15, 9, 9, 15, 15, 8, 13, 15, 15, 15, 4, 4, 4, 4, 15, 4, 4, 4, 4, 4, 15, 15, 15, 15, 3, 3, 3, 15, 15]}\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 5\n",
    "model_checkpoint = \"bert-base-cased\"   # change to 'distilbert-base-cased' or other if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "# alignment function\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    labels = example[\"labels\"]\n",
    "    # join tokens with space for tokenizer but we will use token-level alignment via word_ids\n",
    "    # encode with is_split_into_words=True to preserve original tokenization\n",
    "    tokenized_inputs = tokenizer(tokens, is_split_into_words=True, truncation=True, padding=False)\n",
    "    word_ids = tokenized_inputs.word_ids(batch_index=0)  # list of word_id per tokenized token\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(label_to_id[\"O\"])\n",
    "        else:\n",
    "            # if new word, use B- or I- as provided (we have token-level BIO already)\n",
    "            lab = labels[word_idx]\n",
    "            aligned_labels.append(label_to_id[lab])\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Test alignment on a single example (debug)\n",
    "print(\"Example tokens:\", dataset[\"train\"][0][\"tokens\"])\n",
    "print(\"Example labels:\", dataset[\"train\"][0][\"labels\"])\n",
    "print(tokenize_and_align_labels(dataset[\"train\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63508b55-d975-4b87-9ad2-d82da8e01a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785cc8a511cd4da198725a942198b427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1d1211a6a7485abf8fe8eef899d67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1905f5ceb4cc4d66b147e9d25ed7be3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 14\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook cell 6\n",
    "def hf_tokenize_align(batch):\n",
    "    tokenized = tokenizer(batch[\"tokens\"], is_split_into_words=True, truncation=True)\n",
    "    all_labels = []\n",
    "    for i, label_seq in enumerate(batch[\"labels\"]):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "        aligned = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned.append(-100)                         # ignore in loss\n",
    "            else:\n",
    "                aligned.append(label_to_id[label_seq[word_idx]])\n",
    "        all_labels.append(aligned)\n",
    "    tokenized[\"labels\"] = all_labels\n",
    "    return tokenized\n",
    "\n",
    "tokenized_datasets = dataset.map(hf_tokenize_align, batched=True, remove_columns=[\"tokens\",\"labels\"])\n",
    "\n",
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734fc51b-4994-4ca4-9aaf-a6a0c7626fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/tiny-distilbert-base-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at sshleifer/tiny-distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 2]) in the checkpoint and torch.Size([16, 2]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([16]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    "    ignore_mismatched_sizes=True,   # <- try this first\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531963e-76a9-415a-ad99-92b64299cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3afa6b-59c7-44b4-80ea-cc8e21e0d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ping huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a54a34-26ef-4178-a278-b3dcba461c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 8\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "# Convert predicted ids to label strings and compute seqeval metrics\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # predictions: [batch_size, seq_len, num_labels] -> argmax\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_preds = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        lab = labels[i]\n",
    "        pred = preds[i]\n",
    "        # iterate tokens and skip label == -100 if present (but we didn't set -100 earlier)\n",
    "        seq_true = []\n",
    "        seq_pred = []\n",
    "        for j, lab_id in enumerate(lab):\n",
    "            # if label is -100 (ignored), skip. In our pipeline, we used label_to_id only.\n",
    "            if lab_id == -100:\n",
    "                continue\n",
    "            seq_true.append(id_to_label[int(lab_id)])\n",
    "            seq_pred.append(id_to_label[int(pred[j])])\n",
    "        true_labels.append(seq_true)\n",
    "        true_preds.append(seq_pred)\n",
    "\n",
    "    results = seqeval.compute(predictions=true_preds, references=true_labels)\n",
    "    # results is dict with per-entity results and overall\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results.get(\"overall_accuracy\", 0.0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ddeb453-f3c4-40ac-9d3f-552f32bd6162",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Notebook cell 9\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      3\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/finetuned-bert-job-ner\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m      7\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      8\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      9\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     10\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     11\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     12\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     14\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# Notebook cell 9\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/finetuned-bert-job-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c32f5-cc54-47bb-b6c2-23fc366dfa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 10\n",
    "metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(metrics)\n",
    "\n",
    "trainer.save_model(\"models/finetuned-bert-job-ner\")\n",
    "tokenizer.save_pretrained(\"models/finetuned-bert-job-ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e7bd9-49b5-4346-b9af-27e1ca48d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 11\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp_pipeline = pipeline(\"token-classification\", model=\"models/finetuned-bert-job-ner\", tokenizer=\"models/finetuned-bert-job-ner\", aggregation_strategy=\"none\")\n",
    "\n",
    "def predict_on_raw_text(raw_tokens):\n",
    "    # raw_tokens: list of tokens (same style as dataset tokens)\n",
    "    # For simplicity we join and set is_split_into_words=True when tokenizing\n",
    "    encoding = tokenizer(raw_tokens, is_split_into_words=True, return_offsets_mapping=True, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    outputs = model(**{k:v.to(model.device) for k,v in encoding.items()})\n",
    "    logits = outputs.logits.cpu().numpy()\n",
    "    preds = np.argmax(logits, axis=-1)[0]\n",
    "\n",
    "    word_ids = encoding.word_ids(batch_index=0)\n",
    "    bio_preds = []\n",
    "    for idx, wid in enumerate(word_ids):\n",
    "        if wid is None:\n",
    "            bio_preds.append((\"\",\"O\"))\n",
    "        else:\n",
    "            label = id_to_label[int(preds[idx])]\n",
    "            bio_preds.append((raw_tokens[wid], label))\n",
    "    # compress to one label per original token (skip duplicates from wordpiece)\n",
    "    final = []\n",
    "    last_wid = None\n",
    "    for (tok, lab), pos in zip(bio_preds, range(len(bio_preds))):\n",
    "        # this simplifies â€” better to iterate word ids and pick first occurrence per word\n",
    "        pass\n",
    "\n",
    "# A simpler approach: use our tokenized pipeline above per sentence via the Trainer's predict function:\n",
    "def predict_sentence(tokens_list):\n",
    "    # tokens_list: list of tokens\n",
    "    enc = tokenizer(tokens_list, is_split_into_words=True, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        out = model(**{k:v.to(model.device) for k,v in enc.items()})\n",
    "    logits = out.logits.detach().cpu().numpy()\n",
    "    pred_ids = np.argmax(logits, axis=2)[0]\n",
    "    word_ids = enc.word_ids(batch_index=0)\n",
    "    pred_labels = []\n",
    "    last_word_idx = None\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None:\n",
    "            continue\n",
    "        if word_idx != last_word_idx:\n",
    "            pred_labels.append(id_to_label[int(pred_ids[idx])])\n",
    "            last_word_idx = word_idx\n",
    "    # pred_labels now aligned 1:1 with tokens_list\n",
    "    return list(zip(tokens_list, pred_labels))\n",
    "\n",
    "# Example usage:\n",
    "# tokens = dataset[\"test\"][0][\"tokens\"]\n",
    "# print(predict_sentence(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcc4b2-305e-46f0-9fd5-ed99183e24ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
